{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Bidirectional, Conv1D, MaxPooling1D, Flatten, Concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../data/X_train_lstm.csv\")\n",
    "X_test = pd.read_csv(\"../data/X_test_lstm.csv\")\n",
    "\n",
    "Y_train = pd.read_csv(\"../data/Y_train_lstm.csv\")\n",
    "Y_test = pd.read_csv(\"../data/Y_test_lstm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1107/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 476.4057 - mae: 12.0670\n",
      "Epoch 1: val_loss improved from inf to 376.68182, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 476.1666 - mae: 12.0632 - val_loss: 376.6818 - val_mae: 10.1995\n",
      "Epoch 2/50\n",
      "\u001b[1m1109/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 381.4813 - mae: 10.3305\n",
      "Epoch 2: val_loss improved from 376.68182 to 373.32498, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 381.4779 - mae: 10.3304 - val_loss: 373.3250 - val_mae: 10.0969\n",
      "Epoch 3/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 378.4653 - mae: 10.2366\n",
      "Epoch 3: val_loss improved from 373.32498 to 372.51569, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 378.4619 - mae: 10.2365 - val_loss: 372.5157 - val_mae: 10.0787\n",
      "Epoch 4/50\n",
      "\u001b[1m1105/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 377.0472 - mae: 10.1938\n",
      "Epoch 4: val_loss did not improve from 372.51569\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 377.0415 - mae: 10.1937 - val_loss: 372.7335 - val_mae: 10.1887\n",
      "Epoch 5/50\n",
      "\u001b[1m1106/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 376.1634 - mae: 10.1719\n",
      "Epoch 5: val_loss did not improve from 372.51569\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 376.1594 - mae: 10.1718 - val_loss: 373.4227 - val_mae: 10.1735\n",
      "Epoch 6/50\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 375.5927 - mae: 10.1558\n",
      "Epoch 6: val_loss improved from 372.51569 to 371.96426, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 375.5919 - mae: 10.1558 - val_loss: 371.9643 - val_mae: 10.2072\n",
      "Epoch 7/50\n",
      "\u001b[1m1105/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 375.0011 - mae: 10.1402\n",
      "Epoch 7: val_loss improved from 371.96426 to 371.49466, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 374.9967 - mae: 10.1401 - val_loss: 371.4947 - val_mae: 10.1881\n",
      "Epoch 8/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 374.4921 - mae: 10.1237\n",
      "Epoch 8: val_loss did not improve from 371.49466\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 374.4899 - mae: 10.1237 - val_loss: 371.5028 - val_mae: 10.2196\n",
      "Epoch 9/50\n",
      "\u001b[1m1106/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 374.2728 - mae: 10.1202\n",
      "Epoch 9: val_loss improved from 371.49466 to 370.39401, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 374.2691 - mae: 10.1202 - val_loss: 370.3940 - val_mae: 10.1494\n",
      "Epoch 10/50\n",
      "\u001b[1m1106/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 373.7994 - mae: 10.1046\n",
      "Epoch 10: val_loss did not improve from 370.39401\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 373.7960 - mae: 10.1046 - val_loss: 370.7288 - val_mae: 10.1958\n",
      "Epoch 11/50\n",
      "\u001b[1m1107/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 373.5608 - mae: 10.1014\n",
      "Epoch 11: val_loss improved from 370.39401 to 369.92361, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 373.5581 - mae: 10.1014 - val_loss: 369.9236 - val_mae: 10.1961\n",
      "Epoch 12/50\n",
      "\u001b[1m1107/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 373.3400 - mae: 10.0974\n",
      "Epoch 12: val_loss improved from 369.92361 to 369.69846, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 373.3371 - mae: 10.0973 - val_loss: 369.6985 - val_mae: 10.1636\n",
      "Epoch 13/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 372.9143 - mae: 10.0828\n",
      "Epoch 13: val_loss improved from 369.69846 to 369.17130, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 372.9122 - mae: 10.0828 - val_loss: 369.1713 - val_mae: 10.2063\n",
      "Epoch 14/50\n",
      "\u001b[1m1109/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 372.7721 - mae: 10.0822\n",
      "Epoch 14: val_loss did not improve from 369.17130\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 372.7707 - mae: 10.0822 - val_loss: 369.6129 - val_mae: 10.1499\n",
      "Epoch 15/50\n",
      "\u001b[1m1104/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 372.5589 - mae: 10.0744\n",
      "Epoch 15: val_loss improved from 369.17130 to 368.66537, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 372.5543 - mae: 10.0744 - val_loss: 368.6654 - val_mae: 10.1664\n",
      "Epoch 16/50\n",
      "\u001b[1m1106/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 372.2572 - mae: 10.0735\n",
      "Epoch 16: val_loss did not improve from 368.66537\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 372.2541 - mae: 10.0734 - val_loss: 368.7281 - val_mae: 10.1402\n",
      "Epoch 17/50\n",
      "\u001b[1m1109/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 372.2073 - mae: 10.0672\n",
      "Epoch 17: val_loss improved from 368.66537 to 368.49020, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 372.2060 - mae: 10.0672 - val_loss: 368.4902 - val_mae: 10.1001\n",
      "Epoch 18/50\n",
      "\u001b[1m1107/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 371.9526 - mae: 10.0635\n",
      "Epoch 18: val_loss improved from 368.49020 to 368.27109, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 371.9501 - mae: 10.0635 - val_loss: 368.2711 - val_mae: 10.1446\n",
      "Epoch 19/50\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 371.8461 - mae: 10.0620\n",
      "Epoch 19: val_loss did not improve from 368.27109\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 371.8454 - mae: 10.0620 - val_loss: 368.3900 - val_mae: 10.1211\n",
      "Epoch 20/50\n",
      "\u001b[1m1105/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 371.6873 - mae: 10.0563\n",
      "Epoch 20: val_loss did not improve from 368.27109\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 371.6840 - mae: 10.0563 - val_loss: 368.3429 - val_mae: 10.1480\n",
      "Epoch 21/50\n",
      "\u001b[1m1107/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 371.5186 - mae: 10.0535\n",
      "Epoch 21: val_loss improved from 368.27109 to 368.04230, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 371.5164 - mae: 10.0535 - val_loss: 368.0423 - val_mae: 10.1051\n",
      "Epoch 22/50\n",
      "\u001b[1m1109/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 371.2727 - mae: 10.0461\n",
      "Epoch 22: val_loss improved from 368.04230 to 367.71588, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 371.2716 - mae: 10.0461 - val_loss: 367.7159 - val_mae: 10.0836\n",
      "Epoch 23/50\n",
      "\u001b[1m1109/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 371.2265 - mae: 10.0464\n",
      "Epoch 23: val_loss did not improve from 367.71588\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 371.2254 - mae: 10.0464 - val_loss: 367.8554 - val_mae: 10.1025\n",
      "Epoch 24/50\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 371.2041 - mae: 10.0449\n",
      "Epoch 24: val_loss improved from 367.71588 to 367.68671, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 371.2035 - mae: 10.0449 - val_loss: 367.6867 - val_mae: 10.0968\n",
      "Epoch 25/50\n",
      "\u001b[1m1107/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 371.0227 - mae: 10.0424\n",
      "Epoch 25: val_loss improved from 367.68671 to 367.16733, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 371.0203 - mae: 10.0423 - val_loss: 367.1673 - val_mae: 10.0331\n",
      "Epoch 26/50\n",
      "\u001b[1m1104/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 370.8181 - mae: 10.0379\n",
      "Epoch 26: val_loss did not improve from 367.16733\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 370.8143 - mae: 10.0379 - val_loss: 367.2304 - val_mae: 10.0374\n",
      "Epoch 27/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 370.7761 - mae: 10.0372\n",
      "Epoch 27: val_loss improved from 367.16733 to 367.02493, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 370.7744 - mae: 10.0372 - val_loss: 367.0249 - val_mae: 10.0836\n",
      "Epoch 28/50\n",
      "\u001b[1m1106/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 370.4989 - mae: 10.0340\n",
      "Epoch 28: val_loss improved from 367.02493 to 366.47668, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 370.4962 - mae: 10.0340 - val_loss: 366.4767 - val_mae: 9.9917\n",
      "Epoch 29/50\n",
      "\u001b[1m1105/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 370.3441 - mae: 10.0298\n",
      "Epoch 29: val_loss did not improve from 366.47668\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 370.3416 - mae: 10.0298 - val_loss: 366.6471 - val_mae: 10.0718\n",
      "Epoch 30/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 370.5208 - mae: 10.0313\n",
      "Epoch 30: val_loss improved from 366.47668 to 366.07419, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 370.5191 - mae: 10.0313 - val_loss: 366.0742 - val_mae: 9.9742\n",
      "Epoch 31/50\n",
      "\u001b[1m1107/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 370.3285 - mae: 10.0229\n",
      "Epoch 31: val_loss did not improve from 366.07419\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 370.3260 - mae: 10.0229 - val_loss: 366.4076 - val_mae: 10.0294\n",
      "Epoch 32/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 370.1360 - mae: 10.0250\n",
      "Epoch 32: val_loss did not improve from 366.07419\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 370.1343 - mae: 10.0250 - val_loss: 366.3231 - val_mae: 10.0021\n",
      "Epoch 33/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 370.0855 - mae: 10.0257\n",
      "Epoch 33: val_loss improved from 366.07419 to 365.66229, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 370.0837 - mae: 10.0257 - val_loss: 365.6623 - val_mae: 10.0168\n",
      "Epoch 34/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 369.9232 - mae: 10.0189\n",
      "Epoch 34: val_loss improved from 365.66229 to 365.64005, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 369.9214 - mae: 10.0189 - val_loss: 365.6400 - val_mae: 9.9693\n",
      "Epoch 35/50\n",
      "\u001b[1m1104/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 369.9921 - mae: 10.0204\n",
      "Epoch 35: val_loss improved from 365.64005 to 365.16904, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 369.9875 - mae: 10.0203 - val_loss: 365.1690 - val_mae: 10.0080\n",
      "Epoch 36/50\n",
      "\u001b[1m1109/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 369.6864 - mae: 10.0160\n",
      "Epoch 36: val_loss did not improve from 365.16904\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 369.6852 - mae: 10.0160 - val_loss: 365.5019 - val_mae: 10.0265\n",
      "Epoch 37/50\n",
      "\u001b[1m1105/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 369.5802 - mae: 10.0133\n",
      "Epoch 37: val_loss did not improve from 365.16904\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 369.5769 - mae: 10.0133 - val_loss: 365.3565 - val_mae: 9.9819\n",
      "Epoch 38/50\n",
      "\u001b[1m1107/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 369.5522 - mae: 10.0111\n",
      "Epoch 38: val_loss did not improve from 365.16904\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 369.5501 - mae: 10.0111 - val_loss: 365.3089 - val_mae: 9.9503\n",
      "Epoch 39/50\n",
      "\u001b[1m1105/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 369.6779 - mae: 10.0151\n",
      "Epoch 39: val_loss improved from 365.16904 to 364.87726, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 369.6745 - mae: 10.0151 - val_loss: 364.8773 - val_mae: 9.9696\n",
      "Epoch 40/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 369.5258 - mae: 10.0132\n",
      "Epoch 40: val_loss did not improve from 364.87726\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 369.5240 - mae: 10.0132 - val_loss: 365.2838 - val_mae: 9.9945\n",
      "Epoch 41/50\n",
      "\u001b[1m1106/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 369.4359 - mae: 10.0062\n",
      "Epoch 41: val_loss did not improve from 364.87726\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 369.4329 - mae: 10.0062 - val_loss: 365.3178 - val_mae: 9.9676\n",
      "Epoch 42/50\n",
      "\u001b[1m1107/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 369.2638 - mae: 10.0062\n",
      "Epoch 42: val_loss improved from 364.87726 to 364.57669, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 369.2614 - mae: 10.0062 - val_loss: 364.5767 - val_mae: 9.9639\n",
      "Epoch 43/50\n",
      "\u001b[1m1107/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 369.1380 - mae: 10.0094\n",
      "Epoch 43: val_loss improved from 364.57669 to 364.38449, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 369.1359 - mae: 10.0094 - val_loss: 364.3845 - val_mae: 9.9867\n",
      "Epoch 44/50\n",
      "\u001b[1m1107/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 369.1666 - mae: 10.0096\n",
      "Epoch 44: val_loss did not improve from 364.38449\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 369.1644 - mae: 10.0096 - val_loss: 364.5543 - val_mae: 9.9524\n",
      "Epoch 45/50\n",
      "\u001b[1m1105/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 368.8509 - mae: 9.9959\n",
      "Epoch 45: val_loss improved from 364.38449 to 364.26154, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 368.8480 - mae: 9.9958 - val_loss: 364.2615 - val_mae: 9.9249\n",
      "Epoch 46/50\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 368.8962 - mae: 9.9976\n",
      "Epoch 46: val_loss did not improve from 364.26154\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 368.8957 - mae: 9.9976 - val_loss: 364.6382 - val_mae: 9.9525\n",
      "Epoch 47/50\n",
      "\u001b[1m1106/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 368.9918 - mae: 10.0005\n",
      "Epoch 47: val_loss improved from 364.26154 to 363.98096, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 368.9891 - mae: 10.0005 - val_loss: 363.9810 - val_mae: 9.9389\n",
      "Epoch 48/50\n",
      "\u001b[1m1105/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 368.7810 - mae: 9.9973\n",
      "Epoch 48: val_loss did not improve from 363.98096\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 368.7779 - mae: 9.9973 - val_loss: 364.2881 - val_mae: 9.9257\n",
      "Epoch 49/50\n",
      "\u001b[1m1106/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 368.5787 - mae: 9.9921\n",
      "Epoch 49: val_loss did not improve from 363.98096\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 368.5762 - mae: 9.9921 - val_loss: 364.1656 - val_mae: 9.9116\n",
      "Epoch 50/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 368.4494 - mae: 9.9926\n",
      "Epoch 50: val_loss improved from 363.98096 to 363.47473, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 368.4481 - mae: 9.9926 - val_loss: 363.4747 - val_mae: 9.9140\n",
      "\u001b[1m3827/3827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 340.9279 - mae: 9.5896\n",
      "Test Mean Absolute Error: 9.854459762573242\n",
      "\u001b[1m3827/3827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step\n",
      "Mean Absolute Error for each column:\n",
      "[16.55082161  3.49857578  0.20630951  9.70525263 19.31134326]\n"
     ]
    }
   ],
   "source": [
    "# Defining callbacks\n",
    "checkpoint = ModelCheckpoint(\"../models/lstm_model.keras\", monitor='val_loss', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "# Define LSTM model\n",
    "# Up to 2 layers of LSTM and number of hidden units were hand tuned to determine this as the optimum model\n",
    "lstm_model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], 1)),\n",
    "    LSTM(units=64, activation='relu', recurrent_dropout=0.2),\n",
    "    Dense(5)\n",
    "])\n",
    "\n",
    "# Use MSE for loss because we want to emphasize the \"wrongest\" guesses the most. MAE is an interpretable metric\n",
    "lstm_model.compile(optimizer=Adam(learning_rate=1e-3), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train model w/ early stopping\n",
    "# Batch size is the average number of flights per day\n",
    "history = lstm_model.fit(X_train, Y_train, epochs=50, batch_size=265, validation_split=0.2, callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "\n",
    "loss, mae = lstm_model.evaluate(X_test, Y_test)\n",
    "print(\"Test Mean Absolute Error:\", mae)\n",
    "\n",
    "Y_pred = lstm_model.predict(X_test)\n",
    "\n",
    "mae_columns = mean_absolute_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "print(\"Mean Absolute Error for each column:\")\n",
    "print(mae_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1109/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 994.3939 - mae: 19.4989\n",
      "Epoch 1: val_loss improved from inf to 380.10315, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - loss: 993.5950 - mae: 19.4887 - val_loss: 380.1031 - val_mae: 10.5792\n",
      "Epoch 2/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 387.6837 - mae: 10.8249\n",
      "Epoch 2: val_loss improved from 380.10315 to 374.93298, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 387.6754 - mae: 10.8246 - val_loss: 374.9330 - val_mae: 10.2969\n",
      "Epoch 3/50\n",
      "\u001b[1m1109/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 382.0375 - mae: 10.5333\n",
      "Epoch 3: val_loss improved from 374.93298 to 374.36658, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 382.0348 - mae: 10.5332 - val_loss: 374.3666 - val_mae: 10.3270\n",
      "Epoch 4/50\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 379.8482 - mae: 10.4391\n",
      "Epoch 4: val_loss improved from 374.36658 to 372.95203, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 379.8472 - mae: 10.4391 - val_loss: 372.9520 - val_mae: 10.2862\n",
      "Epoch 5/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 378.6250 - mae: 10.3874\n",
      "Epoch 5: val_loss improved from 372.95203 to 372.13190, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 378.6221 - mae: 10.3874 - val_loss: 372.1319 - val_mae: 10.2170\n",
      "Epoch 6/50\n",
      "\u001b[1m1106/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 380.1126 - mae: 10.3788\n",
      "Epoch 6: val_loss did not improve from 372.13190\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 380.1132 - mae: 10.3789 - val_loss: 372.4745 - val_mae: 10.2701\n",
      "Epoch 7/50\n",
      "\u001b[1m1106/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 377.9700 - mae: 10.3309\n",
      "Epoch 7: val_loss improved from 372.13190 to 372.00204, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 377.9648 - mae: 10.3308 - val_loss: 372.0020 - val_mae: 10.2958\n",
      "Epoch 8/50\n",
      "\u001b[1m1107/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 376.8256 - mae: 10.2892\n",
      "Epoch 8: val_loss improved from 372.00204 to 370.95819, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 376.8222 - mae: 10.2892 - val_loss: 370.9582 - val_mae: 10.2693\n",
      "Epoch 9/50\n",
      "\u001b[1m1106/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 376.1874 - mae: 10.2634\n",
      "Epoch 9: val_loss improved from 370.95819 to 370.56952, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 376.1836 - mae: 10.2634 - val_loss: 370.5695 - val_mae: 10.2342\n",
      "Epoch 10/50\n",
      "\u001b[1m1109/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 375.9489 - mae: 10.2431\n",
      "Epoch 10: val_loss improved from 370.56952 to 370.48895, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 375.9472 - mae: 10.2431 - val_loss: 370.4890 - val_mae: 10.3393\n",
      "Epoch 11/50\n",
      "\u001b[1m1109/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 375.6431 - mae: 10.2349\n",
      "Epoch 11: val_loss did not improve from 370.48895\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 375.6413 - mae: 10.2349 - val_loss: 370.5467 - val_mae: 10.0449\n",
      "Epoch 12/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 375.4287 - mae: 10.2010\n",
      "Epoch 12: val_loss improved from 370.48895 to 369.85385, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 375.4261 - mae: 10.2010 - val_loss: 369.8539 - val_mae: 10.2191\n",
      "Epoch 13/50\n",
      "\u001b[1m1109/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 374.6321 - mae: 10.1941\n",
      "Epoch 13: val_loss did not improve from 369.85385\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 374.6307 - mae: 10.1941 - val_loss: 370.1585 - val_mae: 10.2870\n",
      "Epoch 14/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 374.5606 - mae: 10.1789\n",
      "Epoch 14: val_loss improved from 369.85385 to 369.12308, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 374.5584 - mae: 10.1788 - val_loss: 369.1231 - val_mae: 10.1862\n",
      "Epoch 15/50\n",
      "\u001b[1m1109/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 374.0836 - mae: 10.1635\n",
      "Epoch 15: val_loss improved from 369.12308 to 368.83017, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 374.0824 - mae: 10.1635 - val_loss: 368.8302 - val_mae: 10.1626\n",
      "Epoch 16/50\n",
      "\u001b[1m1106/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 373.7873 - mae: 10.1449\n",
      "Epoch 16: val_loss improved from 368.83017 to 368.60034, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 373.7834 - mae: 10.1449 - val_loss: 368.6003 - val_mae: 10.2048\n",
      "Epoch 17/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 373.5972 - mae: 10.1363\n",
      "Epoch 17: val_loss did not improve from 368.60034\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 373.5949 - mae: 10.1363 - val_loss: 368.7900 - val_mae: 10.1670\n",
      "Epoch 18/50\n",
      "\u001b[1m1109/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 373.1680 - mae: 10.1178\n",
      "Epoch 18: val_loss improved from 368.60034 to 368.40488, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 373.1666 - mae: 10.1178 - val_loss: 368.4049 - val_mae: 10.2585\n",
      "Epoch 19/50\n",
      "\u001b[1m1107/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 372.9780 - mae: 10.1129\n",
      "Epoch 19: val_loss improved from 368.40488 to 368.11368, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 372.9751 - mae: 10.1128 - val_loss: 368.1137 - val_mae: 10.2437\n",
      "Epoch 20/50\n",
      "\u001b[1m1106/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 372.8859 - mae: 10.1048\n",
      "Epoch 20: val_loss improved from 368.11368 to 367.95508, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 372.8823 - mae: 10.1047 - val_loss: 367.9551 - val_mae: 10.2168\n",
      "Epoch 21/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 372.4371 - mae: 10.0933\n",
      "Epoch 21: val_loss improved from 367.95508 to 367.91956, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 372.4352 - mae: 10.0933 - val_loss: 367.9196 - val_mae: 10.2158\n",
      "Epoch 22/50\n",
      "\u001b[1m1107/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 372.3681 - mae: 10.0879\n",
      "Epoch 22: val_loss did not improve from 367.91956\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 372.3656 - mae: 10.0878 - val_loss: 367.9959 - val_mae: 10.1750\n",
      "Epoch 23/50\n",
      "\u001b[1m1107/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 372.3036 - mae: 10.0839\n",
      "Epoch 23: val_loss improved from 367.91956 to 367.56354, saving model to ../models/lstm_model.keras\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 372.3007 - mae: 10.0839 - val_loss: 367.5635 - val_mae: 10.1871\n",
      "Epoch 24/50\n",
      "\u001b[1m1106/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 372.1435 - mae: 10.0798\n",
      "Epoch 24: val_loss did not improve from 367.56354\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 372.1401 - mae: 10.0797 - val_loss: 367.8893 - val_mae: 10.1795\n",
      "Epoch 25/50\n",
      "\u001b[1m1107/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 372.0139 - mae: 10.0768\n",
      "Epoch 25: val_loss did not improve from 367.56354\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 372.0114 - mae: 10.0768 - val_loss: 367.8919 - val_mae: 10.1924\n",
      "Epoch 26/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 371.6202 - mae: 10.0651\n",
      "Epoch 26: val_loss did not improve from 367.56354\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 371.6184 - mae: 10.0651 - val_loss: 367.7513 - val_mae: 10.1634\n",
      "Epoch 27/50\n",
      "\u001b[1m1106/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 371.6694 - mae: 10.0635\n",
      "Epoch 27: val_loss did not improve from 367.56354\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 371.6661 - mae: 10.0635 - val_loss: 367.5886 - val_mae: 10.2049\n",
      "Epoch 28/50\n",
      "\u001b[1m1108/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 371.3645 - mae: 10.0608\n",
      "Epoch 28: val_loss did not improve from 367.56354\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 371.3628 - mae: 10.0608 - val_loss: 367.6993 - val_mae: 10.2052\n",
      "Epoch 28: early stopping\n",
      "\u001b[1m3827/3827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 344.9881 - mae: 9.8242\n",
      "Test Mean Absolute Error: 10.123146057128906\n",
      "\u001b[1m3827/3827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step\n",
      "Mean Absolute Error for each column:\n",
      "[17.03179755  3.68275628  0.2161058   9.86357395 19.82153519]\n"
     ]
    }
   ],
   "source": [
    "# Defining callbacks\n",
    "checkpoint = ModelCheckpoint(\"../models/bilstm_model.keras\", monitor='val_loss', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "# Define LSTM model\n",
    "# Up to 2 layers of LSTM and number of hidden units were hand tuned to determine this as the optimum model\n",
    "bilstm_model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], 1)),\n",
    "    Bidirectional(\n",
    "        LSTM(units=64, activation='relu', recurrent_dropout=0.2)\n",
    "    ),\n",
    "    Dense(5)\n",
    "])\n",
    "\n",
    "# Use MSE for loss because we want to emphasize the \"wrongest\" guesses the most. MAE is an interpretable metric\n",
    "bilstm_model.compile(optimizer=Adam(learning_rate=1e-3), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train model w/ early stopping\n",
    "# Batch size is the average number of flights per day\n",
    "history = bilstm_model.fit(X_train, Y_train, epochs=50, batch_size=265, validation_split=0.2, callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "\n",
    "loss, mae = bilstm_model.evaluate(X_test, Y_test)\n",
    "print(\"Test Mean Absolute Error:\", mae)\n",
    "\n",
    "Y_pred = bilstm_model.predict(X_test)\n",
    "\n",
    "mae_columns = mean_absolute_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "print(\"Mean Absolute Error for each column:\")\n",
    "print(mae_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN + LSTM Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m570/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 928.0755 - mae: 17.2504\n",
      "Epoch 1: val_loss improved from inf to 405.37177, saving model to ../models/hybrid_model.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 923.7798 - mae: 17.2057 - val_loss: 405.3718 - val_mae: 11.0990\n",
      "Epoch 2/50\n",
      "\u001b[1m570/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 400.2170 - mae: 11.0901\n",
      "Epoch 2: val_loss improved from 405.37177 to 397.49271, saving model to ../models/hybrid_model.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 400.1458 - mae: 11.0878 - val_loss: 397.4927 - val_mae: 10.6789\n",
      "Epoch 3/50\n",
      "\u001b[1m571/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 385.4915 - mae: 10.5928\n",
      "Epoch 3: val_loss improved from 397.49271 to 386.89297, saving model to ../models/hybrid_model.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 385.4766 - mae: 10.5925 - val_loss: 386.8930 - val_mae: 10.3141\n",
      "Epoch 4/50\n",
      "\u001b[1m572/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 383.0492 - mae: 10.5345\n",
      "Epoch 4: val_loss improved from 386.89297 to 386.35864, saving model to ../models/hybrid_model.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 383.0411 - mae: 10.5344 - val_loss: 386.3586 - val_mae: 9.9887\n",
      "Epoch 5/50\n",
      "\u001b[1m573/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 382.0531 - mae: 10.5258\n",
      "Epoch 5: val_loss did not improve from 386.35864\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 382.0468 - mae: 10.5257 - val_loss: 386.4611 - val_mae: 9.8789\n",
      "Epoch 6/50\n",
      "\u001b[1m573/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 381.0859 - mae: 10.5031\n",
      "Epoch 6: val_loss improved from 386.35864 to 385.71976, saving model to ../models/hybrid_model.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 381.0796 - mae: 10.5029 - val_loss: 385.7198 - val_mae: 9.9445\n",
      "Epoch 7/50\n",
      "\u001b[1m573/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 380.6212 - mae: 10.4999\n",
      "Epoch 7: val_loss improved from 385.71976 to 384.94080, saving model to ../models/hybrid_model.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 380.6145 - mae: 10.4997 - val_loss: 384.9408 - val_mae: 9.8906\n",
      "Epoch 8/50\n",
      "\u001b[1m573/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 380.2180 - mae: 10.4867\n",
      "Epoch 8: val_loss improved from 384.94080 to 382.96750, saving model to ../models/hybrid_model.keras\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 380.2113 - mae: 10.4865 - val_loss: 382.9675 - val_mae: 9.9041\n",
      "Epoch 9/50\n",
      "\u001b[1m571/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 379.7509 - mae: 10.4554\n",
      "Epoch 9: val_loss did not improve from 382.96750\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 379.7407 - mae: 10.4552 - val_loss: 384.3785 - val_mae: 9.9689\n",
      "Epoch 10/50\n",
      "\u001b[1m573/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 379.3448 - mae: 10.4360\n",
      "Epoch 10: val_loss did not improve from 382.96750\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 379.3385 - mae: 10.4358 - val_loss: 385.3560 - val_mae: 10.1031\n",
      "Epoch 11/50\n",
      "\u001b[1m573/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 379.1324 - mae: 10.4252\n",
      "Epoch 11: val_loss did not improve from 382.96750\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 379.1252 - mae: 10.4250 - val_loss: 385.9130 - val_mae: 10.2537\n",
      "Epoch 12/50\n",
      "\u001b[1m572/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 378.9425 - mae: 10.4317\n",
      "Epoch 12: val_loss did not improve from 382.96750\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 378.9321 - mae: 10.4313 - val_loss: 384.0938 - val_mae: 10.4083\n",
      "Epoch 13/50\n",
      "\u001b[1m571/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 378.4724 - mae: 10.4185\n",
      "Epoch 13: val_loss did not improve from 382.96750\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 378.4601 - mae: 10.4180 - val_loss: 383.3406 - val_mae: 10.4681\n",
      "Epoch 13: early stopping\n",
      "\u001b[1m3827/3827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 358.3213 - mae: 10.1261\n",
      "Test Mean Absolute Error: 10.38701343536377\n",
      "\u001b[1m3827/3827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step\n",
      "Mean Absolute Error for each column:\n",
      "[15.84527384  3.16921887  3.63223434  9.65820891 19.63012625]\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"../models/hybrid_model.keras\", monitor='val_loss', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "# Define input layer\n",
    "input_layer = Input(shape=(X_train.shape[1], 1))\n",
    "\n",
    "# CNN model\n",
    "conv_layer = Conv1D(filters=32, kernel_size=3, activation='relu')(input_layer)\n",
    "maxpool_layer = MaxPooling1D(pool_size=2)(conv_layer)\n",
    "flatten_layer = Flatten()(maxpool_layer)\n",
    "dense_cnn = Dense(32, activation='relu')(flatten_layer)\n",
    "\n",
    "# BiLSTM model\n",
    "lstm_layer = LSTM(64, activation='relu')(input_layer)\n",
    "# lstm_layer2 = LSTM(32, activation='relu', return_sequences=False)(lstm_layer)\n",
    "dense_lstm = Dense(32, activation='relu')(lstm_layer)\n",
    "\n",
    "# Concatenate CNN and BiLSTM outputs\n",
    "concatenated = Concatenate()([dense_cnn, dense_lstm])\n",
    "\n",
    "# Output layer\n",
    "output_layer = Dense(5)(concatenated)\n",
    "\n",
    "# Create the ensemble model\n",
    "hybrid_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "hybrid_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "history = hybrid_model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=50,\n",
    "    batch_size=512,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")\n",
    "\n",
    "loss, mae = hybrid_model.evaluate(X_test, Y_test)\n",
    "print(\"Test Mean Absolute Error:\", mae)\n",
    "\n",
    "Y_pred = hybrid_model.predict(X_test)\n",
    "\n",
    "mae_columns = mean_absolute_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "print(\"Mean Absolute Error for each column:\")\n",
    "print(mae_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flight_delay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
